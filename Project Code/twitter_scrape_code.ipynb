{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/JustAnotherArchivist/snscrape.git\n",
      "  Cloning https://github.com/JustAnotherArchivist/snscrape.git to c:\\users\\harry trinh\\appdata\\local\\temp\\pip-req-build-yzhmi65b\n",
      "  Resolved https://github.com/JustAnotherArchivist/snscrape.git to commit f9a3fafb3fe44986e81bb0f8b7024de1a2fa065d\n",
      "Requirement already satisfied: requests[socks] in c:\\users\\harry trinh\\documents\\anaconda\\lib\\site-packages (from snscrape==0.3.5.dev121+gf9a3faf) (2.24.0)\n",
      "Requirement already satisfied: lxml in c:\\users\\harry trinh\\documents\\anaconda\\lib\\site-packages (from snscrape==0.3.5.dev121+gf9a3faf) (4.6.1)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\harry trinh\\documents\\anaconda\\lib\\site-packages (from snscrape==0.3.5.dev121+gf9a3faf) (4.9.3)\n",
      "Requirement already satisfied: pytz in c:\\users\\harry trinh\\documents\\anaconda\\lib\\site-packages (from snscrape==0.3.5.dev121+gf9a3faf) (2020.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\harry trinh\\documents\\anaconda\\lib\\site-packages (from beautifulsoup4->snscrape==0.3.5.dev121+gf9a3faf) (2.0.1)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\harry trinh\\documents\\anaconda\\lib\\site-packages (from requests[socks]->snscrape==0.3.5.dev121+gf9a3faf) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\harry trinh\\documents\\anaconda\\lib\\site-packages (from requests[socks]->snscrape==0.3.5.dev121+gf9a3faf) (1.25.11)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\harry trinh\\documents\\anaconda\\lib\\site-packages (from requests[socks]->snscrape==0.3.5.dev121+gf9a3faf) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\harry trinh\\documents\\anaconda\\lib\\site-packages (from requests[socks]->snscrape==0.3.5.dev121+gf9a3faf) (2020.6.20)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in c:\\users\\harry trinh\\documents\\anaconda\\lib\\site-packages (from requests[socks]->snscrape==0.3.5.dev121+gf9a3faf) (1.7.1)\n",
      "Building wheels for collected packages: snscrape\n",
      "  Building wheel for snscrape (setup.py): started\n",
      "  Building wheel for snscrape (setup.py): finished with status 'done'\n",
      "  Created wheel for snscrape: filename=snscrape-0.3.5.dev121+gf9a3faf-py3-none-any.whl size=51366 sha256=187ac6e3eb10c9a56959f4273ccfacd53893f46cdf7e28f4268b4bde4fec08cf\n",
      "  Stored in directory: C:\\Users\\Harry Trinh\\AppData\\Local\\Temp\\pip-ephem-wheel-cache-kcc2_hcn\\wheels\\92\\42\\87\\33fa9b18f7a75d02643a9ca3743339aec9be28c6796267c7d8\n",
      "Successfully built snscrape\n",
      "Installing collected packages: snscrape\n",
      "Successfully installed snscrape-0.3.5.dev121+gf9a3faf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone -q https://github.com/JustAnotherArchivist/snscrape.git 'C:\\Users\\Harry Trinh\\AppData\\Local\\Temp\\pip-req-build-yzhmi65b'\n",
      "WARNING: You are using pip version 21.2.3; however, version 21.2.4 is available.\n",
      "You should consider upgrading via the 'c:\\users\\harry trinh\\documents\\anaconda\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/JustAnotherArchivist/snscrape.git\n",
      "  Cloning https://github.com/JustAnotherArchivist/snscrape.git to c:\\users\\harry trinh\\appdata\\local\\temp\\pip-req-build-u45dzuwo\n",
      "  Resolved https://github.com/JustAnotherArchivist/snscrape.git to commit f9a3fafb3fe44986e81bb0f8b7024de1a2fa065d\n",
      "Requirement already satisfied: requests[socks] in c:\\users\\harry trinh\\documents\\anaconda\\lib\\site-packages (from snscrape==0.3.5.dev121+gf9a3faf) (2.24.0)\n",
      "Requirement already satisfied: lxml in c:\\users\\harry trinh\\documents\\anaconda\\lib\\site-packages (from snscrape==0.3.5.dev121+gf9a3faf) (4.6.1)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\harry trinh\\documents\\anaconda\\lib\\site-packages (from snscrape==0.3.5.dev121+gf9a3faf) (4.9.3)\n",
      "Requirement already satisfied: pytz in c:\\users\\harry trinh\\documents\\anaconda\\lib\\site-packages (from snscrape==0.3.5.dev121+gf9a3faf) (2020.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\harry trinh\\documents\\anaconda\\lib\\site-packages (from beautifulsoup4->snscrape==0.3.5.dev121+gf9a3faf) (2.0.1)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\harry trinh\\documents\\anaconda\\lib\\site-packages (from requests[socks]->snscrape==0.3.5.dev121+gf9a3faf) (1.25.11)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\harry trinh\\documents\\anaconda\\lib\\site-packages (from requests[socks]->snscrape==0.3.5.dev121+gf9a3faf) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\harry trinh\\documents\\anaconda\\lib\\site-packages (from requests[socks]->snscrape==0.3.5.dev121+gf9a3faf) (2020.6.20)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\harry trinh\\documents\\anaconda\\lib\\site-packages (from requests[socks]->snscrape==0.3.5.dev121+gf9a3faf) (2.10)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in c:\\users\\harry trinh\\documents\\anaconda\\lib\\site-packages (from requests[socks]->snscrape==0.3.5.dev121+gf9a3faf) (1.7.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone -q https://github.com/JustAnotherArchivist/snscrape.git 'C:\\Users\\Harry Trinh\\AppData\\Local\\Temp\\pip-req-build-u45dzuwo'\n",
      "WARNING: You are using pip version 21.2.3; however, version 21.2.4 is available.\n",
      "You should consider upgrading via the 'c:\\users\\harry trinh\\documents\\anaconda\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/JustAnotherArchivist/snscrape.git\n",
    "!pip3 install git+https://github.com/JustAnotherArchivist/snscrape.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tweepy in c:\\users\\harry trinh\\documents\\anaconda\\lib\\site-packages (3.10.0)\n",
      "Requirement already satisfied: six>=1.10.0 in c:\\users\\harry trinh\\documents\\anaconda\\lib\\site-packages (from tweepy) (1.15.0)\n",
      "Requirement already satisfied: requests[socks]>=2.11.1 in c:\\users\\harry trinh\\documents\\anaconda\\lib\\site-packages (from tweepy) (2.24.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\harry trinh\\documents\\anaconda\\lib\\site-packages (from tweepy) (1.3.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\harry trinh\\documents\\anaconda\\lib\\site-packages (from requests-oauthlib>=0.7.0->tweepy) (3.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\harry trinh\\documents\\anaconda\\lib\\site-packages (from requests[socks]>=2.11.1->tweepy) (2020.6.20)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\harry trinh\\documents\\anaconda\\lib\\site-packages (from requests[socks]>=2.11.1->tweepy) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\harry trinh\\documents\\anaconda\\lib\\site-packages (from requests[socks]>=2.11.1->tweepy) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\harry trinh\\documents\\anaconda\\lib\\site-packages (from requests[socks]>=2.11.1->tweepy) (1.25.11)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in c:\\users\\harry trinh\\documents\\anaconda\\lib\\site-packages (from requests[socks]>=2.11.1->tweepy) (1.7.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.3; however, version 21.2.4 is available.\n",
      "You should consider upgrading via the 'c:\\users\\harry trinh\\documents\\anaconda\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\harry trinh\\documents\\anaconda\\lib\\site-packages (1.1.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\harry trinh\\documents\\anaconda\\lib\\site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in c:\\users\\harry trinh\\documents\\anaconda\\lib\\site-packages (from pandas) (2020.1)\n",
      "Requirement already satisfied: numpy>=1.15.4 in c:\\users\\harry trinh\\documents\\anaconda\\lib\\site-packages (from pandas) (1.19.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\harry trinh\\documents\\anaconda\\lib\\site-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.3; however, version 21.2.4 is available.\n",
      "You should consider upgrading via the 'c:\\users\\harry trinh\\documents\\anaconda\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Textblob in c:\\users\\harry trinh\\documents\\anaconda\\lib\\site-packages (0.15.3)\n",
      "Requirement already satisfied: nltk>=3.1 in c:\\users\\harry trinh\\documents\\anaconda\\lib\\site-packages (from Textblob) (3.5)\n",
      "Requirement already satisfied: joblib in c:\\users\\harry trinh\\documents\\anaconda\\lib\\site-packages (from nltk>=3.1->Textblob) (0.17.0)\n",
      "Requirement already satisfied: regex in c:\\users\\harry trinh\\documents\\anaconda\\lib\\site-packages (from nltk>=3.1->Textblob) (2020.10.15)\n",
      "Requirement already satisfied: tqdm in c:\\users\\harry trinh\\documents\\anaconda\\lib\\site-packages (from nltk>=3.1->Textblob) (4.50.2)\n",
      "Requirement already satisfied: click in c:\\users\\harry trinh\\documents\\anaconda\\lib\\site-packages (from nltk>=3.1->Textblob) (7.1.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.3; however, version 21.2.4 is available.\n",
      "You should consider upgrading via the 'c:\\users\\harry trinh\\documents\\anaconda\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/JustAnotherArchivist/snscrape.git\n",
      "  Cloning https://github.com/JustAnotherArchivist/snscrape.git to c:\\users\\harry trinh\\appdata\\local\\temp\\pip-req-build-2lfc20q8\n",
      "  Resolved https://github.com/JustAnotherArchivist/snscrape.git to commit c76f1637ce1d7a154af83495b67ead2559cd5715\n",
      "Requirement already satisfied: requests[socks] in c:\\users\\harry trinh\\documents\\anaconda\\lib\\site-packages (from snscrape==0.3.5.dev123+gc76f163) (2.24.0)\n",
      "Requirement already satisfied: lxml in c:\\users\\harry trinh\\documents\\anaconda\\lib\\site-packages (from snscrape==0.3.5.dev123+gc76f163) (4.6.1)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\harry trinh\\documents\\anaconda\\lib\\site-packages (from snscrape==0.3.5.dev123+gc76f163) (4.9.3)\n",
      "Requirement already satisfied: pytz in c:\\users\\harry trinh\\documents\\anaconda\\lib\\site-packages (from snscrape==0.3.5.dev123+gc76f163) (2020.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\harry trinh\\documents\\anaconda\\lib\\site-packages (from beautifulsoup4->snscrape==0.3.5.dev123+gc76f163) (2.0.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\harry trinh\\documents\\anaconda\\lib\\site-packages (from requests[socks]->snscrape==0.3.5.dev123+gc76f163) (2020.6.20)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\harry trinh\\documents\\anaconda\\lib\\site-packages (from requests[socks]->snscrape==0.3.5.dev123+gc76f163) (1.25.11)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\harry trinh\\documents\\anaconda\\lib\\site-packages (from requests[socks]->snscrape==0.3.5.dev123+gc76f163) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\harry trinh\\documents\\anaconda\\lib\\site-packages (from requests[socks]->snscrape==0.3.5.dev123+gc76f163) (3.0.4)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in c:\\users\\harry trinh\\documents\\anaconda\\lib\\site-packages (from requests[socks]->snscrape==0.3.5.dev123+gc76f163) (1.7.1)\n",
      "Building wheels for collected packages: snscrape\n",
      "  Building wheel for snscrape (setup.py): started\n",
      "  Building wheel for snscrape (setup.py): finished with status 'done'\n",
      "  Created wheel for snscrape: filename=snscrape-0.3.5.dev123+gc76f163-py3-none-any.whl size=51494 sha256=9541bb972628929abb119e0cc500b468e4ed9f53d514ffc9b15e6dcfd87f53f2\n",
      "  Stored in directory: C:\\Users\\Harry Trinh\\AppData\\Local\\Temp\\pip-ephem-wheel-cache-9du8e7a1\\wheels\\92\\42\\87\\33fa9b18f7a75d02643a9ca3743339aec9be28c6796267c7d8\n",
      "Successfully built snscrape\n",
      "Installing collected packages: snscrape\n",
      "  Attempting uninstall: snscrape\n",
      "    Found existing installation: snscrape 0.3.5.dev121+gf9a3faf\n",
      "    Uninstalling snscrape-0.3.5.dev121+gf9a3faf:\n",
      "      Successfully uninstalled snscrape-0.3.5.dev121+gf9a3faf\n",
      "Successfully installed snscrape-0.3.5.dev123+gc76f163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone -q https://github.com/JustAnotherArchivist/snscrape.git 'C:\\Users\\Harry Trinh\\AppData\\Local\\Temp\\pip-req-build-2lfc20q8'\n",
      "WARNING: You are using pip version 21.2.3; however, version 21.2.4 is available.\n",
      "You should consider upgrading via the 'c:\\users\\harry trinh\\documents\\anaconda\\python.exe -m pip install --upgrade pip' command.\n",
      "[nltk_data] Downloading package stopwords to C:\\Users\\Harry\n",
      "[nltk_data]     Trinh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Harry Trinh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\Harry\n",
      "[nltk_data]     Trinh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to C:\\Users\\Harry\n",
      "[nltk_data]     Trinh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "!pip install tweepy\n",
    "!pip install pandas\n",
    "!pip install Textblob\n",
    "# Imports\n",
    "import tweepy\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "import collections\n",
    "\n",
    "import tweepy as tw\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import networkx\n",
    "from textblob import TextBlob\n",
    "\n",
    "!pip install git+https://github.com/JustAnotherArchivist/snscrape.git\n",
    "import snscrape\n",
    "import snscrape.modules.twitter as sntwitter\n",
    "import pandas\n",
    "import textblob\n",
    "from textblob import TextBlob\n",
    "import snscrape.modules.twitter as sntwitter\n",
    "import pandas\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "\n",
    "import re \n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Key Words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bat-Eater</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>China Virus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wuhan Virus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Go Back to China</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Chinese Virus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Asian Virus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Yellow man fever</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Chink Flu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>don't bring the virus here</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Bat Eater</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>China Corona Virus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Yellowmanfever</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ChinkFlu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>bateatingchinese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>secureourborders</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>wuhancoverup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>disgustingchinese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>makethecommiechinesepay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>commieflu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>chopstickschin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Chinacoronavirus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>fuckchina</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>chinaliedpeopledied</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>nukechina</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>burnwuhan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>yellowmanflu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>batmaneatingflu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>damnchinks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>chingchongvirus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>bombchina</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Key Words\n",
       "0                   Bat-Eater \n",
       "1                 China Virus \n",
       "2                 Wuhan Virus \n",
       "3            Go Back to China \n",
       "4               Chinese Virus \n",
       "5                 Asian Virus \n",
       "6            Yellow man fever \n",
       "7                    Chink Flu\n",
       "8   don't bring the virus here\n",
       "9                   Bat Eater \n",
       "10         China Corona Virus \n",
       "11             Yellowmanfever \n",
       "12                    ChinkFlu\n",
       "13           bateatingchinese \n",
       "14            secureourborders\n",
       "15                wuhancoverup\n",
       "16           disgustingchinese\n",
       "17     makethecommiechinesepay\n",
       "18                   commieflu\n",
       "19              chopstickschin\n",
       "20            Chinacoronavirus\n",
       "21                   fuckchina\n",
       "22         chinaliedpeopledied\n",
       "23                   nukechina\n",
       "24                   burnwuhan\n",
       "25                yellowmanflu\n",
       "26             batmaneatingflu\n",
       "27                  damnchinks\n",
       "28            chingchongvirus \n",
       "29                   bombchina"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"Asian_Hate_Words.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Datetime</th>\n",
       "      <th>Tweet Id</th>\n",
       "      <th>Text</th>\n",
       "      <th>Username</th>\n",
       "      <th>num_followers</th>\n",
       "      <th>verified</th>\n",
       "      <th>locationlanguage</th>\n",
       "      <th>num_retweets</th>\n",
       "      <th>source</th>\n",
       "      <th>key word</th>\n",
       "      <th>location</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-06-29 17:29:07+00:00</td>\n",
       "      <td>1409926918833688580</td>\n",
       "      <td>@jerry_dot_ai ðŸ˜†     \\nbut srsly i love than su...</td>\n",
       "      <td>cateliseh</td>\n",
       "      <td>2725</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>Bat-Eater</td>\n",
       "      <td></td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-06-17 15:35:40+00:00</td>\n",
       "      <td>1405549716687843334</td>\n",
       "      <td>@Broly62910746 @globaltimesnews GT's bat-eater...</td>\n",
       "      <td>Bjtheone2</td>\n",
       "      <td>36</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n",
       "      <td>Bat-Eater</td>\n",
       "      <td></td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-06-16 14:56:15+00:00</td>\n",
       "      <td>1405177407892463626</td>\n",
       "      <td>@ixavieruncle You gotta be more specific, coro...</td>\n",
       "      <td>fathur_bot</td>\n",
       "      <td>232</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>Bat-Eater</td>\n",
       "      <td>Jakarta, Indonesia</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-06-03 08:01:03+00:00</td>\n",
       "      <td>1400361875884421125</td>\n",
       "      <td>Just realised thereâ€™s going to be VAR at the E...</td>\n",
       "      <td>cpaul_ffc</td>\n",
       "      <td>982</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>Bat-Eater</td>\n",
       "      <td></td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-05-29 16:11:30+00:00</td>\n",
       "      <td>1398673361874554881</td>\n",
       "      <td>@Knowledgespace6 @ZZhou61 Bat-eater not able t...</td>\n",
       "      <td>Sandyyy17407251</td>\n",
       "      <td>21</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;a href=\"https://mobile.twitter.com\" rel=\"nofo...</td>\n",
       "      <td>Bat-Eater</td>\n",
       "      <td></td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>2020-03-12 14:23:47+00:00</td>\n",
       "      <td>1238108432500219909</td>\n",
       "      <td>@Bubblebathgirl @ReneeDahl5 #BombChina #NukeCh...</td>\n",
       "      <td>N8JRP</td>\n",
       "      <td>301</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>bombchina</td>\n",
       "      <td>Allen Park, MI</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>2020-03-12 04:11:32+00:00</td>\n",
       "      <td>1237954352351973376</td>\n",
       "      <td>#bombchina</td>\n",
       "      <td>pjvdtx</td>\n",
       "      <td>39</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>bombchina</td>\n",
       "      <td>Texas, USA</td>\n",
       "      <td>und</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>2020-03-11 20:18:03+00:00</td>\n",
       "      <td>1237835196038332425</td>\n",
       "      <td>@seanhannity #BombChina #NukeChina #ChinaLies ...</td>\n",
       "      <td>N8JRP</td>\n",
       "      <td>301</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>bombchina</td>\n",
       "      <td>Allen Park, MI</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>2020-03-07 16:47:27+00:00</td>\n",
       "      <td>1236332645027655687</td>\n",
       "      <td>@RealJamesWoods #BanChina #BombChina #NukeChin...</td>\n",
       "      <td>N8JRP</td>\n",
       "      <td>301</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>bombchina</td>\n",
       "      <td>Allen Park, MI</td>\n",
       "      <td>und</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>2020-03-07 16:46:45+00:00</td>\n",
       "      <td>1236332471412719617</td>\n",
       "      <td>Maybe welding the doors shut will fix it. #Ban...</td>\n",
       "      <td>N8JRP</td>\n",
       "      <td>301</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>bombchina</td>\n",
       "      <td>Allen Park, MI</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15280 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Datetime             Tweet Id  \\\n",
       "0   2021-06-29 17:29:07+00:00  1409926918833688580   \n",
       "1   2021-06-17 15:35:40+00:00  1405549716687843334   \n",
       "2   2021-06-16 14:56:15+00:00  1405177407892463626   \n",
       "3   2021-06-03 08:01:03+00:00  1400361875884421125   \n",
       "4   2021-05-29 16:11:30+00:00  1398673361874554881   \n",
       "..                        ...                  ...   \n",
       "187 2020-03-12 14:23:47+00:00  1238108432500219909   \n",
       "188 2020-03-12 04:11:32+00:00  1237954352351973376   \n",
       "189 2020-03-11 20:18:03+00:00  1237835196038332425   \n",
       "190 2020-03-07 16:47:27+00:00  1236332645027655687   \n",
       "191 2020-03-07 16:46:45+00:00  1236332471412719617   \n",
       "\n",
       "                                                  Text         Username  \\\n",
       "0    @jerry_dot_ai ðŸ˜†     \\nbut srsly i love than su...        cateliseh   \n",
       "1    @Broly62910746 @globaltimesnews GT's bat-eater...        Bjtheone2   \n",
       "2    @ixavieruncle You gotta be more specific, coro...       fathur_bot   \n",
       "3    Just realised thereâ€™s going to be VAR at the E...        cpaul_ffc   \n",
       "4    @Knowledgespace6 @ZZhou61 Bat-eater not able t...  Sandyyy17407251   \n",
       "..                                                 ...              ...   \n",
       "187  @Bubblebathgirl @ReneeDahl5 #BombChina #NukeCh...            N8JRP   \n",
       "188                                         #bombchina           pjvdtx   \n",
       "189  @seanhannity #BombChina #NukeChina #ChinaLies ...            N8JRP   \n",
       "190  @RealJamesWoods #BanChina #BombChina #NukeChin...            N8JRP   \n",
       "191  Maybe welding the doors shut will fix it. #Ban...            N8JRP   \n",
       "\n",
       "    num_followers verified locationlanguage num_retweets  \\\n",
       "0            2725    False              NaN            0   \n",
       "1              36    False              NaN            0   \n",
       "2             232    False              NaN            0   \n",
       "3             982    False              NaN            0   \n",
       "4              21    False              NaN            0   \n",
       "..            ...      ...              ...          ...   \n",
       "187           301    False              NaN            2   \n",
       "188            39    False              NaN            0   \n",
       "189           301    False              NaN            2   \n",
       "190           301    False              NaN            1   \n",
       "191           301    False              NaN            0   \n",
       "\n",
       "                                                source    key word  \\\n",
       "0    <a href=\"http://twitter.com/download/iphone\" r...  Bat-Eater    \n",
       "1    <a href=\"http://twitter.com/download/android\" ...  Bat-Eater    \n",
       "2    <a href=\"http://twitter.com/download/iphone\" r...  Bat-Eater    \n",
       "3    <a href=\"http://twitter.com/download/iphone\" r...  Bat-Eater    \n",
       "4    <a href=\"https://mobile.twitter.com\" rel=\"nofo...  Bat-Eater    \n",
       "..                                                 ...         ...   \n",
       "187  <a href=\"http://twitter.com/download/iphone\" r...   bombchina   \n",
       "188  <a href=\"http://twitter.com/download/iphone\" r...   bombchina   \n",
       "189  <a href=\"http://twitter.com/download/iphone\" r...   bombchina   \n",
       "190  <a href=\"http://twitter.com/download/iphone\" r...   bombchina   \n",
       "191  <a href=\"http://twitter.com/download/iphone\" r...   bombchina   \n",
       "\n",
       "               location language  \n",
       "0                             en  \n",
       "1                             en  \n",
       "2    Jakarta, Indonesia       en  \n",
       "3                             en  \n",
       "4                             en  \n",
       "..                  ...      ...  \n",
       "187      Allen Park, MI       en  \n",
       "188          Texas, USA      und  \n",
       "189      Allen Park, MI       en  \n",
       "190      Allen Park, MI      und  \n",
       "191      Allen Park, MI       en  \n",
       "\n",
       "[15280 rows x 12 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def text_query_to_csv(text_query):\n",
    "    # Creation of query method using parameters\n",
    " \n",
    "    tweets_list2 = []\n",
    "# Using TwitterSearchScraper to scrape data and append tweets to list\n",
    "    for i,tweet in enumerate(sntwitter.TwitterSearchScraper(text_query+ \" since:2020-03-01 until:2021-06-30\").get_items()):\n",
    "        if i>1000:\n",
    "            break\n",
    "        tweets_list2.append([tweet.date, tweet.id, tweet.content, tweet.user.username, tweet.user.followersCount,tweet.user.verified, tweet.user.location, tweet.lang,tweet.retweetCount, tweet.source, text_query])\n",
    "    \n",
    "    # Creating a dataframe from the tweets list above\n",
    "    tweets_df2 = pd.DataFrame(tweets_list2, columns=['Datetime', 'Tweet Id', 'Text', 'Username','num_followers','verified',\n",
    "                                                     'location','language','num_retweets','source', 'key word'])\n",
    "    #tweets_df2['key word'] = text_query\n",
    "    return tweets_df2\n",
    "\n",
    "\n",
    "key_words = pd.read_csv(\"Asian_Hate_Words.csv\")\n",
    "scraped_tweets = pd.DataFrame( columns=[ 'Datetime', 'Tweet Id', 'Text', 'Username','num_followers','verified',\n",
    "                                        'location''language','num_retweets', 'source','key word'])\n",
    "\n",
    "for i in range(len(key_words)):\n",
    "    text_query = key_words[\"Key Words\"][i]\n",
    "    df2 = text_query_to_csv(text_query) \n",
    "    \n",
    "    #assigned and calling the function that have the key words from index 1 \n",
    "    scraped_tweets = scraped_tweets.append(df2)\n",
    "\n",
    "ex = scraped_tweets.copy()\n",
    "scraped_tweets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Just realised thereâ€™s going to be VAR at the Euros... and now Iâ€™m starting to think the Wuhan bat-eater was way ahead of his time'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex.iloc[3,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "China Corona Virus            1001\n",
       "Asian Virus                   1001\n",
       "Bat Eater                     1001\n",
       "Chinese Virus                 1001\n",
       "Chinacoronavirus              1001\n",
       "chinaliedpeopledied           1001\n",
       "nukechina                     1001\n",
       "Wuhan Virus                   1001\n",
       "China Virus                   1001\n",
       "fuckchina                     1001\n",
       "Go Back to China              1001\n",
       "Yellow man fever               950\n",
       "don't bring the virus here     907\n",
       "Chink Flu                      747\n",
       "secureourborders               409\n",
       "Bat-Eater                      318\n",
       "chingchongvirus                282\n",
       "commieflu                      255\n",
       "bombchina                      192\n",
       "ChinkFlu                       108\n",
       "wuhancoverup                    55\n",
       "disgustingchinese               33\n",
       "bateatingchinese                 8\n",
       "makethecommiechinesepay          3\n",
       "Yellowmanfever                   1\n",
       "burnwuhan                        1\n",
       "Name: key word, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex['key word'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def clean(x):\n",
    " x = re.sub(r'^RT[\\s]+', '', x)\n",
    " x = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', x)\n",
    " x = re.sub(r'#', '', x)\n",
    " x = re.sub(r'@[A-Za-z0â€“9]+', '', x) \n",
    " return x\n",
    "\n",
    "ex[\"Text\"] = ex[\"Text\"].apply(str)\n",
    "ex[\"Text\"] = ex[\"Text\"].apply(clean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "polarity = lambda x: TextBlob(x).sentiment.polarity\n",
    "subjectivity = lambda x: TextBlob(x).sentiment.subjectivity\n",
    "ex['polarity'] = ex[\"Text\"].apply(polarity)\n",
    "ex['subjectivity'] = ex[\"Text\"].apply(subjectivity)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Letâ€™s plot the results\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = [10, 8]\n",
    "for index, Tweets in enumerate(ex.index):\n",
    " x = ex.polarity.loc[Tweets]\n",
    " y = ex.subjectivity.loc[Tweets]\n",
    " plt.scatter(x, y, color='Red')\n",
    " \n",
    " \n",
    "\n",
    "plt.title('Sentiment Analysis', fontsize = 20)\n",
    "plt.xlabel('â† Negative â€” â€” â€” â€” â€” â€” Positive â†’', fontsize=15)\n",
    "plt.ylabel('â† Facts â€” â€” â€” â€” â€” â€” â€” Opinions â†’', fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ratio(x):\n",
    " if x > 0:\n",
    "     return 'positive'\n",
    " elif x == 0:\n",
    "     return 'neutral'\n",
    " else:\n",
    "     return 'negative'\n",
    "ex['analysis'] = ex['polarity'].apply(ratio)\n",
    "ex['analysis'].value_counts()\n",
    "# Plotting\n",
    "ex['analysis'].value_counts().plot(kind = 'bar')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ratio_2(x):\n",
    " if x <= 1 and x > .5:\n",
    "     return 'mostly opinion'\n",
    " elif x < .5:\n",
    "     return 'mostly fact'\n",
    "    \n",
    "ex['analysis_2'] = ex['subjectivity'].apply(ratio_2)\n",
    "ex['analysis_2'].value_counts()\n",
    "# Plotting\n",
    "ex['analysis_2'].value_counts().plot(kind = 'bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Datetime</th>\n",
       "      <th>Tweet Id</th>\n",
       "      <th>Text</th>\n",
       "      <th>Username</th>\n",
       "      <th>language</th>\n",
       "      <th>source</th>\n",
       "      <th>key word</th>\n",
       "      <th>polarity</th>\n",
       "      <th>subjectivity</th>\n",
       "      <th>analysis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-06-29 17:29:07+00:00</td>\n",
       "      <td>1409926918833688580</td>\n",
       "      <td>_dot_ai ðŸ˜†     \\nbut srsly i love than sum ppl ...</td>\n",
       "      <td>cateliseh</td>\n",
       "      <td>en</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>Bat-Eater</td>\n",
       "      <td>0.487500</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-06-17 15:35:40+00:00</td>\n",
       "      <td>1405549716687843334</td>\n",
       "      <td>62910746  GT's bat-eater spotted!!</td>\n",
       "      <td>Bjtheone2</td>\n",
       "      <td>en</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n",
       "      <td>Bat-Eater</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-06-16 14:56:15+00:00</td>\n",
       "      <td>1405177407892463626</td>\n",
       "      <td>You gotta be more specific, corona is like ch...</td>\n",
       "      <td>fathur_bot</td>\n",
       "      <td>en</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>Bat-Eater</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.389583</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-06-10 02:55:25+00:00</td>\n",
       "      <td>1402821674744139780</td>\n",
       "      <td>other right in front of me. like SRS anti-asia...</td>\n",
       "      <td>gogyisnotonfire</td>\n",
       "      <td>en</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>Bat-Eater</td>\n",
       "      <td>0.265675</td>\n",
       "      <td>0.468452</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-06-03 08:01:03+00:00</td>\n",
       "      <td>1400361875884421125</td>\n",
       "      <td>Just realised thereâ€™s going to be VAR at the E...</td>\n",
       "      <td>cpaul_ffc</td>\n",
       "      <td>en</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>Bat-Eater</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>2020-04-20 03:09:34+00:00</td>\n",
       "      <td>1252071883727659010</td>\n",
       "      <td>BOMBCHINA they have already attacked us!</td>\n",
       "      <td>johnsheltonusa</td>\n",
       "      <td>en</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>bombchina</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>2020-04-19 17:55:01+00:00</td>\n",
       "      <td>1251932326855991298</td>\n",
       "      <td>declarewaronchina bombchina bombthegooks fuckc...</td>\n",
       "      <td>Thephoenixsuns1</td>\n",
       "      <td>und</td>\n",
       "      <td>&lt;a href=\"https://mobile.twitter.com\" rel=\"nofo...</td>\n",
       "      <td>bombchina</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>2020-04-19 13:45:09+00:00</td>\n",
       "      <td>1251869448283226113</td>\n",
       "      <td>BombChina</td>\n",
       "      <td>PMQRRealtor1</td>\n",
       "      <td>und</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n",
       "      <td>bombchina</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>2020-04-19 10:17:20+00:00</td>\n",
       "      <td>1251817147342479360</td>\n",
       "      <td>You going to stay in your house the next 18 ...</td>\n",
       "      <td>LucasLevon</td>\n",
       "      <td>en</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>bombchina</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>2020-04-19 06:41:45+00:00</td>\n",
       "      <td>1251762896465326082</td>\n",
       "      <td>it's an open secret that China is responsible...</td>\n",
       "      <td>ashwinrockstar7</td>\n",
       "      <td>en</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n",
       "      <td>bombchina</td>\n",
       "      <td>-0.066667</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2121 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Datetime             Tweet Id  \\\n",
       "0   2021-06-29 17:29:07+00:00  1409926918833688580   \n",
       "1   2021-06-17 15:35:40+00:00  1405549716687843334   \n",
       "2   2021-06-16 14:56:15+00:00  1405177407892463626   \n",
       "3   2021-06-10 02:55:25+00:00  1402821674744139780   \n",
       "4   2021-06-03 08:01:03+00:00  1400361875884421125   \n",
       "..                        ...                  ...   \n",
       "96  2020-04-20 03:09:34+00:00  1252071883727659010   \n",
       "97  2020-04-19 17:55:01+00:00  1251932326855991298   \n",
       "98  2020-04-19 13:45:09+00:00  1251869448283226113   \n",
       "99  2020-04-19 10:17:20+00:00  1251817147342479360   \n",
       "100 2020-04-19 06:41:45+00:00  1251762896465326082   \n",
       "\n",
       "                                                  Text         Username  \\\n",
       "0    _dot_ai ðŸ˜†     \\nbut srsly i love than sum ppl ...        cateliseh   \n",
       "1                   62910746  GT's bat-eater spotted!!        Bjtheone2   \n",
       "2     You gotta be more specific, corona is like ch...       fathur_bot   \n",
       "3    other right in front of me. like SRS anti-asia...  gogyisnotonfire   \n",
       "4    Just realised thereâ€™s going to be VAR at the E...        cpaul_ffc   \n",
       "..                                                 ...              ...   \n",
       "96            BOMBCHINA they have already attacked us!   johnsheltonusa   \n",
       "97   declarewaronchina bombchina bombthegooks fuckc...  Thephoenixsuns1   \n",
       "98                                           BombChina     PMQRRealtor1   \n",
       "99     You going to stay in your house the next 18 ...       LucasLevon   \n",
       "100   it's an open secret that China is responsible...  ashwinrockstar7   \n",
       "\n",
       "    language                                             source    key word  \\\n",
       "0         en  <a href=\"http://twitter.com/download/iphone\" r...  Bat-Eater    \n",
       "1         en  <a href=\"http://twitter.com/download/android\" ...  Bat-Eater    \n",
       "2         en  <a href=\"http://twitter.com/download/iphone\" r...  Bat-Eater    \n",
       "3         en  <a href=\"http://twitter.com/download/iphone\" r...  Bat-Eater    \n",
       "4         en  <a href=\"http://twitter.com/download/iphone\" r...  Bat-Eater    \n",
       "..       ...                                                ...         ...   \n",
       "96        en  <a href=\"http://twitter.com/download/iphone\" r...   bombchina   \n",
       "97       und  <a href=\"https://mobile.twitter.com\" rel=\"nofo...   bombchina   \n",
       "98       und  <a href=\"http://twitter.com/download/android\" ...   bombchina   \n",
       "99        en  <a href=\"http://twitter.com/download/iphone\" r...   bombchina   \n",
       "100       en  <a href=\"http://twitter.com/download/android\" ...   bombchina   \n",
       "\n",
       "     polarity  subjectivity  analysis  \n",
       "0    0.487500      0.625000         1  \n",
       "1    0.000000      0.000000         0  \n",
       "2    0.066667      0.389583         1  \n",
       "3    0.265675      0.468452         1  \n",
       "4    0.000000      0.100000         0  \n",
       "..        ...           ...       ...  \n",
       "96   0.000000      0.000000         0  \n",
       "97   0.000000      0.000000         0  \n",
       "98   0.000000      0.000000         0  \n",
       "99   0.000000      0.000000         0  \n",
       "100 -0.066667      0.583333        -1  \n",
       "\n",
       "[2121 rows x 10 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "# Plot histogram of the polarity values\n",
    "ex.hist(bins=[-1, -0.75, -0.5, -0.25, 0.25, 0.5, 0.75, 1],\n",
    "             ax=ax,\n",
    "             color=\"purple\")\n",
    "\n",
    "plt.title(\"Sentiments from Tweets\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Datetime</th>\n",
       "      <th>Tweet Id</th>\n",
       "      <th>Text</th>\n",
       "      <th>Username</th>\n",
       "      <th>language</th>\n",
       "      <th>source</th>\n",
       "      <th>key word</th>\n",
       "      <th>polarity</th>\n",
       "      <th>subjectivity</th>\n",
       "      <th>analysis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-06-29 17:29:07+00:00</td>\n",
       "      <td>1409926918833688580</td>\n",
       "      <td>_dot_ai ðŸ˜†     \\nbut srsly i love than sum ppl ...</td>\n",
       "      <td>cateliseh</td>\n",
       "      <td>en</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>Bat-Eater</td>\n",
       "      <td>0.487500</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-06-17 15:35:40+00:00</td>\n",
       "      <td>1405549716687843334</td>\n",
       "      <td>62910746  GT's bat-eater spotted!!</td>\n",
       "      <td>Bjtheone2</td>\n",
       "      <td>en</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n",
       "      <td>Bat-Eater</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-06-16 14:56:15+00:00</td>\n",
       "      <td>1405177407892463626</td>\n",
       "      <td>You gotta be more specific, corona is like ch...</td>\n",
       "      <td>fathur_bot</td>\n",
       "      <td>en</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>Bat-Eater</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.389583</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-06-10 02:55:25+00:00</td>\n",
       "      <td>1402821674744139780</td>\n",
       "      <td>other right in front of me. like SRS anti-asia...</td>\n",
       "      <td>gogyisnotonfire</td>\n",
       "      <td>en</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>Bat-Eater</td>\n",
       "      <td>0.265675</td>\n",
       "      <td>0.468452</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-06-03 08:01:03+00:00</td>\n",
       "      <td>1400361875884421125</td>\n",
       "      <td>Just realised thereâ€™s going to be VAR at the E...</td>\n",
       "      <td>cpaul_ffc</td>\n",
       "      <td>en</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>Bat-Eater</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>2020-04-20 03:09:34+00:00</td>\n",
       "      <td>1252071883727659010</td>\n",
       "      <td>BOMBCHINA they have already attacked us!</td>\n",
       "      <td>johnsheltonusa</td>\n",
       "      <td>en</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>bombchina</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>2020-04-19 17:55:01+00:00</td>\n",
       "      <td>1251932326855991298</td>\n",
       "      <td>declarewaronchina bombchina bombthegooks fuckc...</td>\n",
       "      <td>Thephoenixsuns1</td>\n",
       "      <td>und</td>\n",
       "      <td>&lt;a href=\"https://mobile.twitter.com\" rel=\"nofo...</td>\n",
       "      <td>bombchina</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>2020-04-19 13:45:09+00:00</td>\n",
       "      <td>1251869448283226113</td>\n",
       "      <td>BombChina</td>\n",
       "      <td>PMQRRealtor1</td>\n",
       "      <td>und</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n",
       "      <td>bombchina</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>2020-04-19 10:17:20+00:00</td>\n",
       "      <td>1251817147342479360</td>\n",
       "      <td>You going to stay in your house the next 18 ...</td>\n",
       "      <td>LucasLevon</td>\n",
       "      <td>en</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>bombchina</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>2020-04-19 06:41:45+00:00</td>\n",
       "      <td>1251762896465326082</td>\n",
       "      <td>it's an open secret that China is responsible...</td>\n",
       "      <td>ashwinrockstar7</td>\n",
       "      <td>en</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n",
       "      <td>bombchina</td>\n",
       "      <td>-0.066667</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2121 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Datetime             Tweet Id  \\\n",
       "0   2021-06-29 17:29:07+00:00  1409926918833688580   \n",
       "1   2021-06-17 15:35:40+00:00  1405549716687843334   \n",
       "2   2021-06-16 14:56:15+00:00  1405177407892463626   \n",
       "3   2021-06-10 02:55:25+00:00  1402821674744139780   \n",
       "4   2021-06-03 08:01:03+00:00  1400361875884421125   \n",
       "..                        ...                  ...   \n",
       "96  2020-04-20 03:09:34+00:00  1252071883727659010   \n",
       "97  2020-04-19 17:55:01+00:00  1251932326855991298   \n",
       "98  2020-04-19 13:45:09+00:00  1251869448283226113   \n",
       "99  2020-04-19 10:17:20+00:00  1251817147342479360   \n",
       "100 2020-04-19 06:41:45+00:00  1251762896465326082   \n",
       "\n",
       "                                                  Text         Username  \\\n",
       "0    _dot_ai ðŸ˜†     \\nbut srsly i love than sum ppl ...        cateliseh   \n",
       "1                   62910746  GT's bat-eater spotted!!        Bjtheone2   \n",
       "2     You gotta be more specific, corona is like ch...       fathur_bot   \n",
       "3    other right in front of me. like SRS anti-asia...  gogyisnotonfire   \n",
       "4    Just realised thereâ€™s going to be VAR at the E...        cpaul_ffc   \n",
       "..                                                 ...              ...   \n",
       "96            BOMBCHINA they have already attacked us!   johnsheltonusa   \n",
       "97   declarewaronchina bombchina bombthegooks fuckc...  Thephoenixsuns1   \n",
       "98                                           BombChina     PMQRRealtor1   \n",
       "99     You going to stay in your house the next 18 ...       LucasLevon   \n",
       "100   it's an open secret that China is responsible...  ashwinrockstar7   \n",
       "\n",
       "    language                                             source    key word  \\\n",
       "0         en  <a href=\"http://twitter.com/download/iphone\" r...  Bat-Eater    \n",
       "1         en  <a href=\"http://twitter.com/download/android\" ...  Bat-Eater    \n",
       "2         en  <a href=\"http://twitter.com/download/iphone\" r...  Bat-Eater    \n",
       "3         en  <a href=\"http://twitter.com/download/iphone\" r...  Bat-Eater    \n",
       "4         en  <a href=\"http://twitter.com/download/iphone\" r...  Bat-Eater    \n",
       "..       ...                                                ...         ...   \n",
       "96        en  <a href=\"http://twitter.com/download/iphone\" r...   bombchina   \n",
       "97       und  <a href=\"https://mobile.twitter.com\" rel=\"nofo...   bombchina   \n",
       "98       und  <a href=\"http://twitter.com/download/android\" ...   bombchina   \n",
       "99        en  <a href=\"http://twitter.com/download/iphone\" r...   bombchina   \n",
       "100       en  <a href=\"http://twitter.com/download/android\" ...   bombchina   \n",
       "\n",
       "     polarity  subjectivity  analysis  \n",
       "0    0.487500      0.625000         1  \n",
       "1    0.000000      0.000000         0  \n",
       "2    0.066667      0.389583         1  \n",
       "3    0.265675      0.468452         1  \n",
       "4    0.000000      0.100000         0  \n",
       "..        ...           ...       ...  \n",
       "96   0.000000      0.000000         0  \n",
       "97   0.000000      0.000000         0  \n",
       "98   0.000000      0.000000         0  \n",
       "99   0.000000      0.000000         0  \n",
       "100 -0.066667      0.583333        -1  \n",
       "\n",
       "[2121 rows x 10 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex.iloc[3,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_tweets = ex[ex['analysis']==-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# neg_tweets_facts = neg_tweets[neg_tweets['analysis_2']=='mostly fact']\n",
    "# tweets_opinions = ex[ex['analysis_2']=='mostly opinion']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text            \"As an Asian American myself, I am tired. As a...\n",
       "Username                                            commondefense\n",
       "language                                                       en\n",
       "source          <a href=\"https://mobile.twitter.com\" rel=\"nofo...\n",
       "key word                                               Bat-Eater \n",
       "polarity                                                -0.185714\n",
       "subjectivity                                             0.292857\n",
       "analysis                                                       -1\n",
       "Name: 31, dtype: object"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_tweets.iloc[12,2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Anti-Asian Racism is rampant and unfortunately normalized. â€œBat-eater jokesâ€ and calling the coronavirus the â€œChinese virusâ€ has turned into violent acts against the Asian American Community.'"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_tweets_facts.iloc[23,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Delusional brainwashed stupid bat-eater people who forgot that their country who actually spread this virus '"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_tweets_opinions.iloc[30,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#uncommnet this cell when you're ready to save the data\n",
    "# ex.to_csv('ALL_TWEET_SENTIMENT.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
